\section{Analysis}
\subsection{Accuracy}
User testing determined that the playlists generated were generally of high quality and on par with manual track selection. System generated playlists were generally identified due to the lack of analysis of mood or tempo. A tempo tracking feature could be implemented, as well as a mood discriminating technique such as detailed by \citet*{Liu2003} or a genre classification algorithm such as \citet*{Basili2004}.

Satisfactory results were produced by the similarity metric, a small number of disparate songs were returned in results, usually appearing in playlists as one or two `bad' tracks per 17-track playlist, suggesting a greater amount of training required. This project was limited to a training set of around 100 tracks, which would need to be increased for future development. The automated testing method used, while suitable for a heuristic evaluation of song comparison algorithms, could be further improved using a corpus of music pre-analysed by an expert musicologist \citep{Muellensiefen2004}, affording further insight into perceptual similarity comparisons.

Of the four track comparison algorithms compared, the sorted comparison performed by far the best. To address user's comments on structure in playlist generation, an algorithm which takes this into account may in fact be more appropriate.

The playlist generation technique described overall works well. Playlists generated had good continuity, variance and progression while avoiding the repetition of artists. The system aims to optimise the overall score of the playlist by keeping tracks which work best in the playlist, choosing to remove other, low-scoring tracks. Other techniques based on constraint satisfaction \citep{Vossen2005} and Gaussian mixture modelling \citep{Aucouturier2003} have been implemented to optimise the total score of the playlist, the algorithm designed however is much less intensive and hence better suits the design parameters.
\subsection{Efficacy}
As a whole, the system meets all design requirements set out in the specification. The system processes audio files in a relatively short amount of time, owing to the avoidance of overly expensive features such as MFCCs, this also has implications for data storage. Playlists are generated very quickly, requiring only a matter of seconds to generate a playlist of reasonable length from a library of 1400 tracks. Verifiability and review is achieved by providing a binary file viewer and verbose output options. The system prints scores used in the similarity metric that proved valuable in testing, allowing analysis of any anomalous tracks in the playlist. The command-line interface provides an interface that allows creation of simple test scripts. It is well documented and would be simple for a future developer to understand.
\subsection{Areas for Development}
By nature the metric is an estimation, and hence it would never be possible to create a flawless model of perceptual similarity; nevertheless, the algorithm could be improved by adding specific features addressing tempo, mood and genre.

The data set used for this small-scale test is an example user's media library. Tracks are therefore likely to be of relatively similar genre, due to the user's tastes. A fairer test would involve collecting an equal number of examples of music from all main musical genres.
